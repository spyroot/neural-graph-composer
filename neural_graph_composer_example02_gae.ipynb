{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  %cd /root\n",
    "  !rm -rf /root/neural-graph-composer\n",
    "  !git clone https://github.com/spyroot/neural-graph-composer\n",
    "  %cd neural-graph-composer\n",
    "  !ls\n",
    "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu118.html\n",
    "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu118.html\n",
    "  !pip install torch-geometric\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Author Mus spyroot@gmail.com\n",
    "\"\"\"\n",
    "import argparse\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
    "from neural_graph_composer.midi_dataset import MidiDataset\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class RandomNodeDrop(T.BaseTransform):\n",
    "    \"\"\"Randomly drop nodes from the graph.\"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        \"\"\"\n",
    "        :param p: p (float): The probability of dropping each node.\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        \"\"\"\n",
    "\n",
    "        :param data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # print(f\"Got data {data}\")\n",
    "        num_nodes = data.num_nodes\n",
    "        node_idx = torch.arange(num_nodes)\n",
    "        drop_idx = node_idx[torch.randperm(num_nodes)[:int(self.p * num_nodes)]]\n",
    "        remain_idx = node_idx[~torch.isin(node_idx, drop_idx)]\n",
    "\n",
    "        data.edge_index, data.edge_attr = RandomNodeDrop.filter_adj(\n",
    "            data.edge_index, data.edge_attr, remain_idx, num_nodes)\n",
    "        data.x = data.x[remain_idx]\n",
    "        data.y = data.y[remain_idx]\n",
    "\n",
    "        data.train_mask = data.train_mask[remain_idx]\n",
    "        data.val_mask = data.val_mask[remain_idx]\n",
    "        data.test_mask = data.test_mask[remain_idx]\n",
    "        data.num_nodes = data.x.shape[0]\n",
    "\n",
    "        # print(f\"called return data {data}\")\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_adj(\n",
    "            edge_index: torch.Tensor,\n",
    "            edge_attr: Optional[torch.Tensor], keep_idx: torch.Tensor,\n",
    "            num_nodes: Optional[int] = None) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = int(edge_index.max()) + 1\n",
    "\n",
    "        mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        mask[keep_idx] = 1\n",
    "        row, col = edge_index\n",
    "        mask_row = mask[row]\n",
    "        mask_col = mask[col]\n",
    "        mask_all = mask_row & mask_col\n",
    "        if edge_attr is not None:\n",
    "            return edge_index[:, mask_all], edge_attr[mask_all]\n",
    "        else:\n",
    "            return edge_index[:, mask_all]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "\n",
    "\n",
    "class RandomEdgeDrop(T.BaseTransform):\n",
    "    def __init__(self, p=0.5):\n",
    "        \"\"\"\n",
    "        :param p:\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, data):\n",
    "        \"\"\"\n",
    "        :param data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_edges = data.edge_index.shape[1]\n",
    "        mask = torch.rand(num_edges) >= self.p\n",
    "\n",
    "        edge_index = data.edge_index[:, mask]\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            edge_attr = data.edge_attr[mask]\n",
    "\n",
    "        pos_edge_mask = None\n",
    "        neg_edge_mask = None\n",
    "        if data.pos_edge_label is not None and data.neg_edge_label is not None:\n",
    "            pos_edge_mask = data.pos_edge_label_index[:, mask]\n",
    "            neg_edge_mask = data.neg_edge_label_index[:, mask]\n",
    "\n",
    "        return Data(\n",
    "            x=data.x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=data.y,\n",
    "            pos_edge_label=data.pos_edge_label,\n",
    "            neg_edge_label=data.neg_edge_label,\n",
    "            train_mask=data.train_mask,\n",
    "            val_mask=data.val_mask,\n",
    "            test_mask=data.test_mask,\n",
    "            pos_edge_label_index=pos_edge_mask,\n",
    "            neg_edge_label_index=neg_edge_mask,\n",
    "            node_hash=data.node_hash\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    \"\"\"GCN Encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    \"\"\"VAE GCN Encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "\n",
    "class LinearEncoder(torch.nn.Module):\n",
    "    \"\"\" Liner GCN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.conv(x, edge_index)\n",
    "\n",
    "\n",
    "class VariationalLinearEncoder(torch.nn.Module):\n",
    "    \"\"\" VariationalLinearEncoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_mu = GCNConv(in_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "\n",
    "def train(train_data, model, optimizer, args):\n",
    "    \"\"\"\n",
    "    :param train_data:\n",
    "    :param model:\n",
    "    :param optimizer:\n",
    "    :param args:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    # z = model.encode(train_data.x, train_data.edge_index.long())\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index)\n",
    "    if args.variational:\n",
    "        loss = loss + (1 / train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data, model):\n",
    "    \"\"\"\n",
    "    :param data:\n",
    "    :param model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "    pos_indices = data.pos_edge_label_index.t()\n",
    "    neg_indices = data.neg_edge_label_index.t()\n",
    "\n",
    "    all_indices = torch.cat([pos_indices, neg_indices], dim=0)\n",
    "    y_true = torch.zeros((len(all_indices),), dtype=torch.long)\n",
    "    y_true[:pos_indices.size(0)] = 1\n",
    "\n",
    "    all_indices = all_indices.to(torch.long)\n",
    "    edge_index = torch.stack([all_indices[:, 0], all_indices[:, 1]], dim=0)\n",
    "\n",
    "    #\n",
    "    y_pred = model.decoder(z, edge_index)\n",
    "    y_pred = (y_pred > 0.5).type(torch.long)\n",
    "    acc = (y_pred == y_true).sum().item() / y_true.size(0)\n",
    "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index), acc\n",
    "\n",
    "\n",
    "def predict_link(model, x, edge_index, node_a, node_b):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param x:\n",
    "    :param edge_index:\n",
    "    :param node_a:\n",
    "    :param node_b:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model.encode(x, edge_index)\n",
    "    similarity = torch.sigmoid(torch.dot(z[node_a], z[node_b]))\n",
    "    return similarity.item()\n",
    "\n",
    "\n",
    "def node_clustering(model, x, edge_index, num_clusters):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param x:\n",
    "    :param edge_index:\n",
    "    :param num_clusters:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model.encode(x, edge_index)\n",
    "    embeddings = z.detach().cpu().numpy()\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    clusters = kmeans.fit_predict(embeddings)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def visualize_embeddings(model, x, edge_index):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param x:\n",
    "    :param edge_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model.encode(x, edge_index)\n",
    "    embeddings = z.detach().cpu().numpy()\n",
    "\n",
    "    tsne = TSNE(n_components=2)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], s=20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    :param args:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = T.Compose([\n",
    "        T.NormalizeFeatures(),\n",
    "        T.ToDevice(device),\n",
    "        RandomNodeDrop(p=0.1),\n",
    "        T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                          split_labels=True, add_negative_train_samples=False),\n",
    "    ])\n",
    "\n",
    "    dataset = MidiDataset(root=\"./data\", transform=transform)\n",
    "    batch_size = 2\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    in_channels, out_channels = dataset.num_features, 32\n",
    "\n",
    "    if not args.variational and not args.linear:\n",
    "        model = GAE(GCNEncoder(in_channels, out_channels))\n",
    "        print(\"Creating GAE with GCNEncoder\")\n",
    "    elif not args.variational and args.linear:\n",
    "        model = GAE(LinearEncoder(in_channels, out_channels))\n",
    "        print(\"Creating GA with LinearEncoder\")\n",
    "    elif args.variational and not args.linear:\n",
    "        model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
    "        print(\"Creating VGAE with VariationalGCNEncoder\")\n",
    "    elif args.variational and args.linear:\n",
    "        model = VGAE(VariationalLinearEncoder(in_channels, out_channels))\n",
    "        print(\"Creating VGAE with VariationalLinearEncoder\")\n",
    "\n",
    "    models = [\n",
    "        (\"GAE with GCNEncoder\", GAE(GCNEncoder(in_channels, out_channels))),\n",
    "        (\"GAE with LinearEncoder\", GAE(LinearEncoder(in_channels, out_channels))),\n",
    "        (\"VGAE with VariationalGCNEncoder\", VGAE(VariationalGCNEncoder(in_channels, out_channels))),\n",
    "        (\"VGAE with VariationalLinearEncoder\", VGAE(VariationalLinearEncoder(in_channels, out_channels))),\n",
    "    ]\n",
    "\n",
    "    for model_name, model in models:\n",
    "        model = model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "        test_x_list = []\n",
    "        test_edge_index_list = []\n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            train_loss = 0\n",
    "            for batch in dataloader:\n",
    "                train_data, val_data, test_data = batch\n",
    "                loss = train(train_data, model, optimizer, args)\n",
    "                train_loss += loss\n",
    "                metric, acc = test(test_data, model)\n",
    "                auc, ap = metric\n",
    "                print(f'Epoch: {epoch:03d}, Model: {model_name: <40}, Loss: {loss:.4f}, '\n",
    "                      f'AUC: {auc:.4f}, AP: {ap:.4f}, ACC: {acc:.4f}')\n",
    "                if epoch == 1:\n",
    "                    test_x_list.append(test_data.x)\n",
    "                    test_edge_index_list.append(test_data.edge_index)\n",
    "\n",
    "            # for batch in dataloader:\n",
    "            #     train_data, val_data, test_data = batch\n",
    "            # train_loss /= len(dataloader)\n",
    "            # metric_val, acc_val = test(val_data, model)\n",
    "            # auc_val, ap_val = metric_val\n",
    "\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, ')\n",
    "\n",
    "            if epoch % args.save_interval == 0:\n",
    "                torch.save(model.state_dict(), f'{model_name}_epoch_{epoch}.pt')\n",
    "\n",
    "    test_x = torch.cat(test_x_list, dim=0)\n",
    "    test_edge_index = torch.cat(test_edge_index_list, dim=1)\n",
    "    combined_test_data = Data(x=test_x, edge_index=test_edge_index)\n",
    "\n",
    "    node_a_index, node_b_index = 5, 10\n",
    "    node_a_hash = dataset.index_to_hash[node_a_index]\n",
    "    node_b_hash = dataset.index_to_hash[node_b_index]\n",
    "\n",
    "    note_a = dataset.notes_to_hash[node_a_hash]\n",
    "    note_b = dataset.notes_to_hash[node_b_hash]\n",
    "    print(dataset.hash_to_notes)\n",
    "\n",
    "    similarity = predict_link(\n",
    "        model, combined_test_data.x,\n",
    "        combined_test_data.edge_index,\n",
    "        node_a_index, node_b_index)\n",
    "\n",
    "    print(f'Similarity between node with hash {note_a} '\n",
    "          f'and node with hash {note_b}: {similarity}')\n",
    "\n",
    "    # num_clusters = 5\n",
    "    # clusters = node_clustering(model, combined_test_data.x, combined_test_data.edge_index, num_clusters)\n",
    "    # print(f'Node clusters: {clusters}')\n",
    "    # visualize_embeddings(model, combined_test_data.x, combined_test_data.edge_index)\n",
    "\n",
    "\n",
    "def random_edge_drop_checker():\n",
    "    \"\"\"Validate random edge  drop.  It should be less num edges.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    transform = RandomEdgeDrop(p=0.5)\n",
    "    dataset = MidiDataset(root=\"./data\")\n",
    "    dataset.transform = transform\n",
    "    dataloader = DataLoader(dataset, batch_size=2)\n",
    "    # Check number of nodes before and after RandomNodeDrop transformation\n",
    "    for batch in dataloader:\n",
    "        data = batch[0]\n",
    "        print(\"Number of nodes before transformation:\", data.edge_index)\n",
    "        data = transform(data)\n",
    "        print(\"Number of nodes after transformation:\", data.edge_index)\n",
    "\n",
    "\n",
    "def random_node_drop_checker():\n",
    "    \"\"\"Validate random drop is working.  It should be less number of nodes\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    transform = RandomNodeDrop(p=0.5)\n",
    "    dataset = MidiDataset(root=\"./data\")\n",
    "    dataset.transform = transform\n",
    "    dataloader = DataLoader(dataset, batch_size=2)\n",
    "    # Check number of nodes before and after RandomNodeDrop transformation\n",
    "    for batch in dataloader:\n",
    "        data = batch[0]\n",
    "        print(\"Number of nodes before transformation:\", data.num_nodes)\n",
    "        data = transform(data)\n",
    "        print(\"Number of nodes after transformation:\", data.num_nodes)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--variational', action='store_true')\n",
    "parser.add_argument('--linear', action='store_true')\n",
    "parser.add_argument('--epochs', type=int, default=400)\n",
    "parser.add_argument('--save_interval', type=int, default=200)\n",
    "args = parser.parse_args()\n",
    "main(args)\n",
    "\n",
    "# # Predict link between node_a and node_b\n",
    "# node_a, node_b = 5, 10\n",
    "# similarity = predict_link(model, test_data.x, test_data.edge_index, node_a, node_b)\n",
    "# print(f'Similarity between node {node_a} and {node_b}: {similarity}')\n",
    "#\n",
    "# # Perform node clustering\n",
    "# num_clusters = 5\n",
    "# clusters = node_clustering(model, test_data.x, test_data.edge_index, num_clusters)\n",
    "# print(f'Node clusters: {clusters}')\n",
    "#\n",
    "# # Visualize embeddings\n",
    "# visualize_embeddings(model, test_data.x, test_data.edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
